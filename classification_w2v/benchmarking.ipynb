{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"r8-train-all-terms.txt\"\n",
    "TEST_PATH = \"r8-test-all-terms.txt\"\n",
    "\n",
    "TRAIN_PATH = \"r8-train-no-stop.txt\"\n",
    "TEST_PATH = \"r8-test-no-stop.txt\"\n",
    "WORD_VECTORS_PATH = \"glove.6B.50d.txt\"\n",
    "# WORD_VECTORS_PATH = \"glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "with open(TRAIN_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        X_train.append(text.split())\n",
    "        y_train.append(label)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "X_test, y_test = [], []\n",
    "with open(TEST_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        X_test.append(text.split())\n",
    "        y_test.append(label)\n",
    "        \n",
    "    \n",
    "all_words = set(w for words in (X_train + X_test) for w in words)\n",
    "X_train = X_train[:250]\n",
    "y_train = y_train[:250]\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = {}\n",
    "with open(WORD_VECTORS_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        if word in all_words:\n",
    "            w2v[word] = np.array(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_vec = np.array([\n",
    "        np.mean([w2v[k] for k in kws if k in w2v], axis=0)\n",
    "        for kws in X_train\n",
    "    ])\n",
    "\n",
    "X_test_vec = np.array([\n",
    "        np.mean([w2v[k] for k in kws if k in w2v], axis=0)\n",
    "        for kws in X_test\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark(clf, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = (pred == y_test).mean()\n",
    "    return score\n",
    "\n",
    "def benchmark_vec(clf):\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    pred = clf.predict(X_test_vec)\n",
    "    score = (pred == y_test).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mult_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "\n",
    "mult_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb_tfifd = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88761991777067151,\n",
       " 0.58611238008222932,\n",
       " 0.66331658291457285,\n",
       " 0.58611238008222932)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mult_nb), benchmark(bern_nb), benchmark(mult_nb_tfidf), benchmark(bern_nb_tfifd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8423937871174052"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_vec(RandomForestClassifier(n_estimators=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84878940155322069"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_vec(ExtraTreesClassifier(n_estimators=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78529008679762446"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_vec(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multi_multi_nb' from 'multi_multi_nb.pyc'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multi_multi_nb as mm\n",
    "reload(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86888990406578348"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mm.MMGNB(w2v, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.494746459571\n",
      "0.01 0.494746459571\n",
      "0.05 0.00456829602558\n",
      "0.1 0.868889904066\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.001, 0.01, 0.05, 0.1]:\n",
    "    print alpha, benchmark(mm.MMGNB(w2v, alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76838739150296942"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mm.MMGNB(w2v, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.881224303335\n",
      "0.01 0.895386021014\n",
      "0.05 0.906349931476\n",
      "0.1 0.909090909091\n",
      "0.2 0.905893101873\n",
      "0.5 0.903152124258\n",
      "1 0.887619917771\n",
      "2 0.871174052079\n",
      "5 0.845134764733\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5]:\n",
    "    clf = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), \n",
    "                    (\"multinomial nb\", MultinomialNB(alpha=alpha))])\n",
    "    print alpha, benchmark(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'earn': 464, 'acq': 307, 'crude': 75, 'interest': 44, 'ship': 38, 'trade': 35, 'money-fx': 32, 'grain': 5})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'earn': 141, 'acq': 67, 'trade': 13, 'crude': 13, 'grain': 5, 'money-fx': 4, 'interest': 4, 'ship': 3})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multi_multi_kernel_nb' from 'multi_multi_kernel_nb.pyc'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multi_multi_kernel_nb as mmk\n",
    "reload(mmk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49748743718592964"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "benchmark(mmk.MMGKNB(w2v, sigma=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.808588396528\n",
      "0.5 0.857012334399\n",
      "1 0.861123800822\n",
      "2 0.68935587026\n",
      "5 0.494746459571\n",
      "10 0.494746459571\n",
      "20 0.494746459571\n"
     ]
    }
   ],
   "source": [
    "for sigma in [0.2, 0.5, 1, 2, 5, 10, 20]:\n",
    "    clf = mmk.MMGKNB(w2v, sigma=sigma)\n",
    "    print sigma, benchmark(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = {}\n",
    "with open(WORD_VECTORS_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        w2v[word] = np.array(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X_train1 = [['cat', 'dog', 'hamster'],\n",
    "            ['paris', 'berlin', 'london']]\n",
    "y_train1 = ['pets',\n",
    "           'capitals']\n",
    "X_test1 = [['parrot', 'goldfish'],\n",
    "           ['london', 'madrid']]\n",
    "y_test1 = np.array(['pets', 'capitals'])\n",
    "print benchmark(mm.MMGNB(w2v, 0.1, 0.1), X_train1, y_train1, X_test1, y_test1)\n",
    "print benchmark(mmk.MMGKNB(w2v), X_train1, y_train1, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.75019307"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(w2v['paris'] - w2v['france'] - w2v['berlin'] + w2v['germany']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = mm.MMGNB(w2v, 0.1 ,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pets'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_one(['cow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
